{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision import transforms as transforms\n",
    "import torchvision.transforms.functional as tf\n",
    "\n",
    "from window.utils.tiling import create_tile_list\n",
    "from window.models.yolo_for_inference import YoloClass\n",
    "from window.postprocess.match_truths import match_results_to_truths, match_yolo_to_truths\n",
    "from window.utils.drawing import draw_results_on_image\n",
    "from window.utils.truths import windows_truth\n",
    "from window.utils.inference_windows import process_annotation_df_negative_inference, create_windows_from_yolo, windows_to_whole_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_base_dir = \"/home/cmf21/pytorch_save/GFRC/Bin/rgb_baseline2/\"\n",
    "#output_base_dir = \"/home/cmf21/pytorch_save/GFRC/Bin/meta_prediction/\"\n",
    "output_base_dir = \"/home/cmf21/pytorch_save/GFRC/Bin/meta_prediction_norm/\"\n",
    "\n",
    "valid_whole_image_dir = \"/data/old_home_dir/ChrissyF/GFRC/Valid/whole_images_all/\"\n",
    "truth_file = \"/data/old_home_dir/ChrissyF/GFRC/yolo_valid_GFRC_bboxes.csv\"\n",
    "\n",
    "output_dir = output_base_dir + \"valid_images_out/\"\n",
    "output_csv = output_dir + \"results_matched_nms.csv\"\n",
    "\n",
    "# get all image files\n",
    "image_files = list(Path(valid_whole_image_dir).glob(\"*.jpg\"))\n",
    "image_files = [img.name for img in image_files]\n",
    "\n",
    "# Process truth files\n",
    "truths = pd.read_csv(truth_file)\n",
    "truths.loc[:, 'filename'] = [strin.replace('/', '_') for strin in truths.file_loc]\n",
    "\n",
    "# create yolo model\n",
    "#saveweightspath = output_base_dir + \"testing_save_163.pt\"\n",
    "#saveweightspath = output_base_dir + \"testing_save_132.pt\"\n",
    "saveweightspath = output_base_dir + \"testing_save_127.pt\"\n",
    "channels_in = 4\n",
    "yolo_model = YoloClass(wtpath=saveweightspath, channels=channels_in)\n",
    "\n",
    "# create empty list to store results\n",
    "results_all_ims = pd.DataFrame(columns=['xmn', 'xmx', 'ymn', 'ymx', 'conf', 'confmat', 'tru_box', 'filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-scholar",
   "metadata": {},
   "outputs": [],
   "source": [
    "if channels_in > 3:\n",
    "    image_data = pd.read_csv('/home/cmf21/pytorch_save/GFRC/preds_for_cnn.csv')\n",
    "    metacolumns = ['prediction_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-saying",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fl in image_files:\n",
    "    truths_im = truths[truths.filename == fl]\n",
    "    truths_im_pixels = windows_truth(truths_im)\n",
    "\n",
    "    # Per image\n",
    "    print(fl)\n",
    "    whole_im = cv2.imread(valid_whole_image_dir + fl)\n",
    "    whole_im = cv2.cvtColor(whole_im, cv2.COLOR_BGR2RGB)\n",
    "    if channels_in > 3:\n",
    "        whole_im = np.divide(whole_im, 255.0)\n",
    "        matched_row = image_data[image_data.image_name == fl]\n",
    "        fillval = matched_row[metacolumns]\n",
    "        fillvals = np.expand_dims(fillval, axis=0)\n",
    "        new_channel = np.ones((whole_im.shape[0], whole_im.shape[1], len(metacolumns)))\n",
    "        new_channel = np.multiply(new_channel, fillvals)\n",
    "        whole_im = np.dstack((whole_im, new_channel))\n",
    "        whole_im = np.array(whole_im, dtype=np.float32)\n",
    "\n",
    "    # create tiles\n",
    "    tilez = create_tile_list(whole_im)\n",
    "\n",
    "    # get predictions from yolo\n",
    "    boxes_whole_im = yolo_model.inference_on_image(tilez, 0.3)\n",
    "    \n",
    "    windows_whole_im = windows_to_whole_im(boxes_whole_im)\n",
    "    \n",
    "    # calculate results\n",
    "    iou_threshold = 0.15\n",
    "    nms_threshold = 0.1\n",
    "    results_per_im = match_yolo_to_truths(windows_whole_im, truths_im_pixels, iou_threshold, nms_threshold)\n",
    "    results_per_im['filename'] = fl\n",
    "\n",
    "    results_all_ims = pd.concat((results_all_ims, results_per_im), axis=0, sort=False)\n",
    "\n",
    "    # draw results on image\n",
    "    if channels_in > 3:\n",
    "        whole_im = whole_im[:, :, 0:3]\n",
    "        whole_im = whole_im * 255\n",
    "    image_out = draw_results_on_image(whole_im, results_per_im)\n",
    "    image_out = cv2.cvtColor(image_out, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(output_dir + fl, image_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all_ims.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f'TP: {np.sum(results_all_ims.confmat==\"TP\")}, FP: {np.sum(results_all_ims.confmat==\"FP\")}, FN: {np.sum(results_all_ims.confmat==\"FN\")}')\n",
    "print(\"number of images:\", len(image_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-triumph",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all_ims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ims = np.unique(results_all_ims.filename)\n",
    "nperim = []\n",
    "tpsim = []\n",
    "for im in unique_ims:\n",
    "    files = results_all_ims[results_all_ims.filename == im]\n",
    "    nperim.append(files.shape[0])\n",
    "    tpsim.append(np.sum(files.confmat == 'TP'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ims[np.argmax(nperim)]\n",
    "# 'Z247_Img14318.jpg'\n",
    "unique_ims[np.argmax(tpsim)]\n",
    "'Z124_Img13083.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-killing",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_im = unique_ims[np.argmax(nperim)]\n",
    "#whole_im = cv2.imread(output_dir + bad_im)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "Image.open(output_dir + bad_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_im = unique_ims[np.argmax(tpsim)]\n",
    "#whole_im = cv2.imread(output_dir + good_im)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "Image.open(output_dir + good_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-twist",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_plus_results_loc = '/home/cmf21/pytorch_save/GFRC/Bin/post_processed/pos_from_yolo/rgb_baseline2_incep/results_post_window_classifier.csv'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "yolo_plus_results = pd.read_csv(yolo_plus_results_loc)\n",
    "yolo_plus_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "unique_ims = np.unique(yolo_plus_results.filename)\n",
    "nperim = []\n",
    "tpsim = []\n",
    "fnsim = []\n",
    "for im in unique_ims:\n",
    "    files = yolo_plus_results[yolo_plus_results.filename == im]\n",
    "    nperim.append(files.shape[0])\n",
    "    tpsim.append(np.sum(files.confmat == 'TP'))\n",
    "    fnsim.append(np.sum(files.confmat == 'FN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unique_ims[np.argmax(nperim)])\n",
    "# Z247_Img14318.jpg\n",
    "print(unique_ims[np.argmax(tpsim)])\n",
    "# Z124_Img13083.jpg\n",
    "print(unique_ims[np.argmax(fnsim)])\n",
    "# Z138_Img02887.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "output_dir = output_base_dir = \"/home/cmf21/pytorch_save/GFRC/Bin/post_processed/pos_from_yolo/rgb_baseline2_incep/valid_results_on_image/\"\n",
    "med_im = unique_ims[np.argmax(fnsim)]\n",
    "whole_im = Image.open(output_dir + med_im)\n",
    "whole_im"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
