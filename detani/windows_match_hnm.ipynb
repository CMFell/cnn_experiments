{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from window.utils.tiling import split_locations_array\n",
    "from window.utils.truths import windows_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-vancouver",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'hnm'\n",
    "\n",
    "filename_gfrc_windows = 'gfrc_' + experiment + '_windows.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_truths_gfrc_hnm(truths):\n",
    "    truths.loc[:, 'filename'] = [strin.replace('/', '_') for strin in truths.file_loc]\n",
    "    truths = windows_truth(truths)\n",
    "    truths['oc'] = truths['oc'].add(1)\n",
    "    truths['tru_class'] = truths['oc']\n",
    "    return truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-camera",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_file_gfrc = \"/data/old_home_dir/ChrissyF/GFRC/yolo_valid_GFRC_bboxes.csv\"\n",
    "gfrc_truth = pd.read_csv(truth_file_gfrc)\n",
    "gfrc_truth = process_truths_gfrc_hnm(gfrc_truth)\n",
    "gfrc_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_whole_image_dir_gfrc = \"/data/old_home_dir/ChrissyF/GFRC/Valid/whole_images_all/\"\n",
    "\n",
    "file_dir = \"/home/cmf21/pytorch_save/output_for_draft/\"\n",
    "\n",
    "gfrc_windows = pd.read_csv(file_dir + filename_gfrc_windows)\n",
    "gfrc_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove class one which is things that look like animals but aren't\n",
    "gfrc_windows = gfrc_windows[gfrc_windows['class'] == 0]\n",
    "gfrc_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms_per_im(boxes_in, thresh, method='mean'):\n",
    "    \n",
    "    boxes_in = boxes_in.sort_values(by='conf', ascending=False)\n",
    "\n",
    "    xmins = boxes_in.xmn\n",
    "    xmaxs = boxes_in.xmx\n",
    "    ymins = boxes_in.ymn\n",
    "    ymaxs = boxes_in.ymx\n",
    "    confs = boxes_in.conf\n",
    "    clazs = boxes_in['class']\n",
    "\n",
    "    boxes_ot = pd.DataFrame(columns=['xmn', 'xmx', 'ymn', 'ymx', 'conf', 'pred_class'])\n",
    "\n",
    "    xmins = np.array(xmins.tolist())\n",
    "    xmaxs = np.array(xmaxs.tolist())\n",
    "    ymins = np.array(ymins.tolist())\n",
    "    ymaxs = np.array(ymaxs.tolist())\n",
    "    confs = np.array(confs.tolist())\n",
    "    clazs = np.array(clazs.tolist())\n",
    "\n",
    "    while len(xmins) > 0:\n",
    "\n",
    "        xmn = xmins[0]\n",
    "        xmns = np.array(xmins[1:])\n",
    "        xmx = xmaxs[0]\n",
    "        xmxs = np.array(xmaxs[1:])\n",
    "        ymn = ymins[0]\n",
    "        ymns = np.array(ymins[1:])\n",
    "        ymx = ymaxs[0]\n",
    "        ymxs = np.array(ymaxs[1:])\n",
    "        cnf = confs[0]\n",
    "        cnfs = np.array(confs[1:])\n",
    "        clz = clazs[0]\n",
    "        clzs = np.array(clazs[1:])\n",
    "\n",
    "        ol_wid = np.minimum(xmx, xmxs) - np.maximum(xmn, xmns)\n",
    "        ol_hei = np.minimum(ymx, ymxs) - np.maximum(ymn, ymns)\n",
    "\n",
    "        ol_x = np.maximum(0, ol_wid)\n",
    "        ol_y = np.maximum(0, ol_hei)\n",
    "\n",
    "        distx = np.subtract(xmxs, xmns)\n",
    "        disty = np.subtract(ymxs, ymns)\n",
    "        bxx = xmx - xmn\n",
    "        bxy = ymx - ymn\n",
    "\n",
    "        ol_area = np.multiply(ol_x, ol_y)\n",
    "        bx_area = bxx * bxy\n",
    "        bxs_area = np.multiply(distx, disty)\n",
    "\n",
    "        ious = np.divide(ol_area, np.subtract(np.add(bxs_area, bx_area), ol_area))\n",
    "        mask_bxs = np.greater(ious, thresh)\n",
    "\n",
    "        if np.sum(mask_bxs) > 0:\n",
    "            box_ot = pd.DataFrame(index=range(1), columns=['xmn', 'xmx', 'ymn', 'ymx', 'conf', 'pred_class'])\n",
    "\n",
    "            xmns = xmns[mask_bxs]\n",
    "            xmxs = xmxs[mask_bxs]\n",
    "            ymns = ymns[mask_bxs]\n",
    "            ymxs = ymxs[mask_bxs]\n",
    "            cnfs = cnfs[mask_bxs]\n",
    "\n",
    "            if method == 'mean':\n",
    "                box_ot.loc[0, 'xmn'] = np.array(np.mean(xmns), dtype=int)\n",
    "                box_ot.loc[0, 'ymn'] = np.array(np.mean(ymns), dtype=int)\n",
    "                box_ot.loc[0, 'xmx'] = np.array(np.mean(xmxs), dtype=int)\n",
    "                box_ot.loc[0, 'ymx'] = np.array(np.mean(ymxs), dtype=int)\n",
    "                box_ot.loc[0, 'conf'] = np.mean(cnfs)\n",
    "                box_ot.loc[0, 'pred_class'] = clz\n",
    "            elif method == 'first':\n",
    "                box_ot.loc[0, 'xmn'] = xmns[0]\n",
    "                box_ot.loc[0, 'ymn'] = ymns[0]\n",
    "                box_ot.loc[0, 'xmx'] = xmxs[0]\n",
    "                box_ot.loc[0, 'ymx'] = ymxs[0]\n",
    "                box_ot.loc[0, 'conf'] = np.max(cnfs)\n",
    "                box_ot.loc[0, 'pred_class'] = clz\n",
    "            else:\n",
    "                box_ot.loc[0, 'xmn'] = np.min(xmns)\n",
    "                box_ot.loc[0, 'ymn'] = np.min(ymns)\n",
    "                box_ot.loc[0, 'xmx'] = np.max(xmxs)\n",
    "                box_ot.loc[0, 'ymx'] = np.max(ymxs)\n",
    "                box_ot.loc[0, 'conf'] = np.max(cnfs)\n",
    "                box_ot.loc[0, 'pred_class'] = clz\n",
    "\n",
    "            mask_out = np.repeat(False, len(xmins))\n",
    "            mask_out[0] = True\n",
    "            mask_out[1:] = mask_bxs\n",
    "            mask_out = np.logical_not(mask_out)\n",
    "\n",
    "            xmins = xmins[mask_out]\n",
    "            xmaxs = xmaxs[mask_out]\n",
    "            ymins = ymins[mask_out]\n",
    "            ymaxs = ymaxs[mask_out]\n",
    "            confs = confs[mask_out]\n",
    "            clazs = clazs[mask_out]\n",
    "            \n",
    "        else:\n",
    "            box_ot = pd.DataFrame(index=range(1), columns=['xmn', 'xmx', 'ymn', 'ymx', 'conf', 'pred_class'])\n",
    "\n",
    "            box_ot.loc[0, 'xmn'] = xmn\n",
    "            box_ot.loc[0, 'ymn'] = ymn\n",
    "            box_ot.loc[0, 'xmx'] = xmx\n",
    "            box_ot.loc[0, 'ymx'] = ymx\n",
    "            box_ot.loc[0, 'conf'] = cnf\n",
    "            box_ot.loc[0, 'pred_class'] = clz\n",
    "\n",
    "            mask_out = np.repeat(False, len(xmins))\n",
    "            mask_out[0] = True\n",
    "            mask_out = np.logical_not(mask_out)\n",
    "            \n",
    "            xmins = xmins[mask_out]\n",
    "            xmaxs = xmaxs[mask_out]\n",
    "            ymins = ymins[mask_out]\n",
    "            ymaxs = ymaxs[mask_out]\n",
    "            confs = confs[mask_out]\n",
    "            clazs = clazs[mask_out]\n",
    "            \n",
    "        #box_ot = box_ot.reset_index(drop=True)\n",
    "        boxes_ot = pd.concat((boxes_ot, box_ot), axis=0, sort=False)\n",
    "\n",
    "    boxes_ot.loc[:, 'filename'] = boxes_in.filename.iloc[0]\n",
    "\n",
    "    return boxes_ot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms_for_yolo(windows_df, nms_thresh, method):\n",
    "    images = np.unique(windows_df.filename)\n",
    "    windows_all_ims = pd.DataFrame(columns=['xmn', 'xmx', 'ymn', 'ymx', 'conf', 'pred_class', 'filename'])\n",
    "    for im in images:\n",
    "        windows_im = windows_df[windows_df.filename == im]\n",
    "        windows_im = nms_per_im(windows_im, nms_thresh, method)\n",
    "        windows_all_ims.append(windows_im)\n",
    "        windows_all_ims = pd.concat((windows_all_ims, windows_im), axis=0, ignore_index=True, sort=False)\n",
    "    return windows_all_ims\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(box1, box2):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xa = max(box1.xmn, box2.xmn)\n",
    "    xb = min(box1.xmx, box2.xmx)\n",
    "    ya = max(box1.ymn, box2.ymn)\n",
    "    yb = min(box1.ymx, box2.ymx)\n",
    "    # compute the area of intersection rectangle\n",
    "    inter_area = max(0, xb - xa + 1) * max(0, yb - ya + 1)\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    box1_area = (box1.xmx - box1.xmn + 1) * (box1.ymx - box1.ymn + 1)\n",
    "    box2_area = (box2.xmx - box2.xmn + 1) * (box2.ymx - box2.ymn + 1)\n",
    "    # compute the intersection over union \n",
    "    iou = inter_area / float(box1_area + box2_area - inter_area)\n",
    "    # return the intersection over union value\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_to_truth_im(detections_df, truth_df, iou_threshold):\n",
    "    \n",
    "    if detections_df.shape[0] > 0:\n",
    "        results_out = pd.DataFrame(columns = ['xmn', 'xmx', 'ymn', 'ymx', 'conf', 'filename', 'pred_class', \n",
    "                                              'tru_class'])\n",
    "        results_per_im = detections_df[['xmn', 'xmx', 'ymn', 'ymx', 'conf', 'filename', 'pred_class']]\n",
    "        results_per_im = results_per_im.reset_index(drop=True)\n",
    "        truths_per_im = truth_df.reset_index(drop=True)\n",
    "        # best match stores the detection with the highest iou\n",
    "        best_match = [False] * results_per_im.shape[0]\n",
    "        # true match stores if the truth overlaps with any detections\n",
    "        true_match = [False] * truth_df.shape[0]\n",
    "        # matchz stores any matches that overlap but aren't the best overlap (not double counting TP, but not adding to FP)\n",
    "        matchz = np.array([True] * results_per_im.shape[0])\n",
    "\n",
    "        for idx, tru in truths_per_im.iterrows():\n",
    "            iouz = []\n",
    "            for res_idx, result in results_per_im.iterrows():\n",
    "                iou = intersection_over_union(tru, result)\n",
    "                iouz.append(iou)\n",
    "            iou_ind = np.argmax(iouz)\n",
    "            if iouz[iou_ind] > iou_threshold:\n",
    "                if not best_match[iou_ind]: \n",
    "                    best_iou_res = results_per_im.iloc[iou_ind:(iou_ind+1), :]\n",
    "                    best_iou_res = best_iou_res.reset_index(drop=True)\n",
    "                    best_iou_res.loc[:, 'confmat'] = 'TP'\n",
    "                    true_box = f'xmin: {tru.xmn}; xmax:{tru.xmx}; ymin: {tru.ymn}; ymax: {tru.ymx}'\n",
    "                    best_iou_res.loc[:, 'tru_box'] = true_box\n",
    "                    best_iou_res.loc[:, 'tru_class'] = tru.tru_class\n",
    "                    results_out = pd.concat((results_out, best_iou_res), axis=0, ignore_index=True, sort=False)\n",
    "                    best_match[iou_ind] = True\n",
    "                    true_match[idx] = True\n",
    "            # matchz removes any matches that overlap but are not the most overlapping\n",
    "            match_mask = np.array(iouz) > iou_threshold\n",
    "            matchz[match_mask] = False\n",
    "\n",
    "        # use matchz to filter results to keep only those that don't overlap with truths\n",
    "        results_per_im = results_per_im[matchz]\n",
    "        results_per_im = results_per_im.reset_index(drop=True)\n",
    "\n",
    "        if results_per_im.shape[0] > 0:\n",
    "            results_per_im['confmat'] = 'FP'\n",
    "            results_per_im['tru_box'] = ''\n",
    "            results_per_im['tru_class'] = 0\n",
    "        results_out = pd.concat((results_out, results_per_im), axis=0, ignore_index=True, sort=False)  \n",
    "        true_match = np.array(true_match)\n",
    "        true_match = np.logical_not(true_match)\n",
    "        if np.sum(true_match) > 0:\n",
    "            false_negatives = truth_df[['xmn', 'xmx', 'ymn', 'ymx', 'filename', 'tru_class']]\n",
    "            false_negatives = false_negatives[true_match]\n",
    "            false_negatives = false_negatives.reset_index(drop=True)\n",
    "            false_negatives.loc[:, 'conf'] = 1.0\n",
    "            false_negatives.loc[:, 'confmat'] = 'FN'\n",
    "            false_negatives.loc[:, 'tru_box'] = ''\n",
    "            false_negatives.loc[:, 'pred_class'] = 0\n",
    "            results_out = pd.concat((results_out, false_negatives), axis=0, ignore_index=True, sort=False)\n",
    "        results_out = results_out.reset_index(drop=True)\n",
    "    else:\n",
    "        results_out = truth_df.loc[:, ['xmn', 'xmx', 'ymn', 'ymx', 'filename', 'tru_class']]\n",
    "        results_out.columns = ['xmn', 'xmx', 'ymn', 'ymx', 'filename', 'tru_class']\n",
    "        results_out.loc[:, 'conf'] = 1\n",
    "        results_out.loc[:, 'confmat'] = 'FN'\n",
    "        results_out.loc[:, 'tru_box'] = ''\n",
    "        results_out.loc[:, 'pred_class'] = 0\n",
    "\n",
    "    return results_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_to_truth(detections_df, truth_df, valid_whole_image_dir, iou_threshold):\n",
    "    image_files_jpg = list(Path(valid_whole_image_dir).glob(\"*.jpg\"))\n",
    "    image_files_png = list(Path(valid_whole_image_dir).glob(\"*.png\"))\n",
    "    image_files = image_files_jpg + image_files_png\n",
    "    image_files = [img.name for img in image_files]\n",
    "    matched_results = pd.DataFrame(columns=['xmn', 'xmx', 'ymn', 'ymx', 'conf', 'filename', 'confmat', 'tru_box', 'pred_class', 'tru_class'])\n",
    "    \n",
    "    for im in image_files:\n",
    "        detections_im = detections_df[detections_df.filename == im]\n",
    "        truth_im = truth_df[truth_df.filename == im]\n",
    "        if detections_im.shape[0] > 0:\n",
    "            # detections and truths need to match\n",
    "            if truth_im.shape[0] > 0:\n",
    "                match_results_im = match_to_truth_im(detections_im, truth_im, iou_threshold)\n",
    "            # detections and no truths - all detections false postive\n",
    "            else:\n",
    "                match_results_im = detections_im[['xmn', 'xmx', 'ymn', 'ymx', 'conf', 'filename', 'pred_class']]\n",
    "                match_results_im['confmat'] = 'FP'\n",
    "                match_results_im['tru_box'] = ''\n",
    "                match_results_im['tru_class'] = 0\n",
    "        else:\n",
    "            # no detections and truths - all truths false negatives\n",
    "            if truth_im.shape[0] > 0:\n",
    "                match_results_im = truth_im[['xmn', 'xmx', 'ymn', 'ymx', 'filename', 'tru_class']]\n",
    "                match_results_im['conf'] = 1.0\n",
    "                match_results_im['confmat'] = 'FN'\n",
    "                match_results_im['tru_box'] = ''\n",
    "                match_results_im['pred_class'] = 0\n",
    "            else:\n",
    "                match_results_im = pd.DataFrame(columns=['xmn', 'xmx', 'ymn', 'ymx', 'conf', 'filename', 'confmat', 'tru_box', 'pred_class', 'tru_class'])\n",
    "        matched_results = pd.concat((matched_results, match_results_im), axis=0, ignore_index=True, sort=False)\n",
    "    \n",
    "    return matched_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_threshold_results(windows_df, truth_df, im_dir, nms_threshold=0.05, iou_threshold=0.25, method='first'):\n",
    "    threshes = np.linspace(0.01, 1, 100)\n",
    "    threshold_array = np.zeros((len(threshes), 8))\n",
    "    image_files_jpg = list(Path(im_dir).glob(\"*.jpg\"))\n",
    "    image_files_png = list(Path(im_dir).glob(\"*.png\"))\n",
    "    image_files = image_files_jpg + image_files_png\n",
    "    image_files = [img.name for img in image_files]\n",
    "    for idx, th in enumerate(threshes):\n",
    "        print(th)\n",
    "        detections_th = windows_df[windows_df.conf > th]\n",
    "        detections_th = nms_for_yolo(detections_th, nms_threshold, method)\n",
    "        result_th = match_to_truth(detections_th, truth_df, im_dir, iou_threshold)\n",
    "        TP = np.sum(result_th.confmat==\"TP\")\n",
    "        FP = np.sum(result_th.confmat==\"FP\")\n",
    "        FN = np.sum(result_th.confmat==\"FN\")\n",
    "        RE = TP / (TP + FN)\n",
    "        PR = TP / (TP + FP)\n",
    "        MR = 1 - RE\n",
    "        FPPI = FP / len(image_files)\n",
    "\n",
    "        list_out = [th, TP, FP, FN, RE, PR, MR, FPPI]\n",
    "\n",
    "        threshold_array[idx, :] = list_out \n",
    "        \n",
    "    threshold_metrics = pd.DataFrame(threshold_array, columns=['threshold', 'TP', 'FP', 'FN', 'RE', 'PR', 'MR', 'FPPI'])\n",
    "    return threshold_metrics\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfrc_metrics = calculate_threshold_results(gfrc_windows, gfrc_truth, valid_whole_image_dir_gfrc, 0.25, 0.25, 'mean')\n",
    "\n",
    "gfrc_metrics[gfrc_metrics.RE > 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfrc_metrics.to_csv(file_dir + 'gfrc_' + experiment + \"_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-intellectual",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfrc_conf_threshold = 0.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_threshold_results(windows_df, truth_df, im_dir, thresh, nms_threshold=0.05, iou_threshold=0.25, method='first'):\n",
    "\n",
    "    image_files_jpg = list(Path(im_dir).glob(\"*.jpg\"))\n",
    "    image_files_png = list(Path(im_dir).glob(\"*.png\"))\n",
    "    image_files = image_files_jpg + image_files_png\n",
    "    image_files = [img.name for img in image_files]\n",
    "    detections_th = windows_df[windows_df.conf > thresh]\n",
    "    detections_th['class'] = detections_th['class'].add(1)\n",
    "    detections_th = nms_for_yolo(detections_th, nms_threshold, method)\n",
    "    result_th = match_to_truth(detections_th, truth_df, im_dir, iou_threshold)\n",
    "\n",
    "    return result_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfrc_results = single_threshold_results(gfrc_windows, gfrc_truth, valid_whole_image_dir_gfrc, gfrc_conf_threshold, 0.25, 0.25, 'mean')\n",
    "gfrc_results.to_csv(file_dir + 'gfrc_' + experiment + \"_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_stats(detections_df):\n",
    "    unique_images = np.unique(detections_df.filename)\n",
    "    tpz = []\n",
    "    fpz = []\n",
    "    fnz = []\n",
    "    for fl in unique_images:\n",
    "        results_per_im = detections_df[detections_df['filename'] == fl]\n",
    "        tpz.append(np.sum(results_per_im.confmat == 'TP'))\n",
    "        fpz.append(np.sum(results_per_im.confmat == 'FP'))\n",
    "        fnz.append(np.sum(results_per_im.confmat == 'FN'))\n",
    "\n",
    "    TPz = np.reshape(np.array(tpz), (len(tpz), 1))\n",
    "    FPz = np.reshape(np.array(fpz), (len(fpz), 1))\n",
    "    FNz = np.reshape(np.array(fnz), (len(fnz), 1))\n",
    "    UIz = np.reshape(unique_images, (len(unique_images), 1))\n",
    "    df_out = pd.DataFrame(np.hstack((UIz, TPz, FPz, FNz)), columns=['filename', 'TP', 'FP', 'FN'])\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfrc_image_results = get_image_stats(gfrc_results)\n",
    "gfrc_image_results.to_csv(file_dir + 'gfrc_' + experiment + \"_image_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfrc_image_results[gfrc_image_results.FN > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from window.utils.drawing import draw_results_on_image\n",
    "\n",
    "def draw_res(results_all_ims, valid_whole_image_dir, image_out_dir, dataset):\n",
    "    images_out = []\n",
    "    fnz_out = []\n",
    "    fpz_out = []\n",
    "\n",
    "    image_files_jpg = list(Path(valid_whole_image_dir).glob(\"*.jpg\"))\n",
    "    image_files_png = list(Path(valid_whole_image_dir).glob(\"*.png\"))\n",
    "    image_files = image_files_jpg + image_files_png\n",
    "    image_files = [img.name for img in image_files]\n",
    "\n",
    "    for fl in image_files:\n",
    "        # Per image\n",
    "        whole_im = cv2.imread(valid_whole_image_dir + fl)\n",
    "        whole_im = cv2.cvtColor(whole_im, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if dataset == 'gfrc':\n",
    "            fl_png = fl\n",
    "        else:\n",
    "            fl_png = fl[:-4] + '.png'\n",
    "\n",
    "        # calculate results\n",
    "        results_per_im = results_all_ims[results_all_ims.filename == fl]\n",
    "\n",
    "        # create list of all false negatives\n",
    "        for rw in range(results_per_im.shape[0]):\n",
    "            row = results_per_im.iloc[rw, :]\n",
    "            if row.confmat == 'FN':\n",
    "                xmn = max(0, row.xmn - 50)\n",
    "                ymn = max(0, row.ymn - 50)\n",
    "                xmx = min(whole_im.shape[1], row.xmx + 50)\n",
    "                ymx = min(whole_im.shape[0], row.ymx + 50)\n",
    "                fn_window = whole_im[row.ymn:row.ymx, row.xmn:row.xmx]\n",
    "                fn_window = cv2.resize(fn_window, (fn_window.shape[1]*2, fn_window.shape[0]*2))\n",
    "                fnz_out.append(fn_window)\n",
    "            if row.confmat == 'FP':\n",
    "                xmn = max(0, row.xmn - 50)\n",
    "                ymn = max(0, row.ymn - 50)\n",
    "                xmx = min(whole_im.shape[1], row.xmx + 50)\n",
    "                ymx = min(whole_im.shape[0], row.ymx + 50)\n",
    "                fp_window = whole_im[row.ymn:row.ymx, row.xmn:row.xmx]\n",
    "                f_window = cv2.resize(fp_window, (fp_window.shape[1]*2, fp_window.shape[0]*2))\n",
    "                fpz_out.append(fp_window)\n",
    "\n",
    "        # draw results on image\n",
    "        image_out = draw_results_on_image(whole_im, results_per_im)\n",
    "        image_out = cv2.resize(image_out, (1840, 1228))\n",
    "        images_out.append(image_out)\n",
    "        image_out = cv2.cvtColor(image_out, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imwrite(str(image_out_dir + fl), image_out)\n",
    "        \n",
    "    return fnz_out, fpz_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfrc_image_outdir = \"/home/cmf21/pytorch_save/output_for_draft/\" + 'gfrc_' + experiment + '_25_25/'\n",
    "gfrc_fnz, gfrc_fpz = draw_res(gfrc_results, valid_whole_image_dir_gfrc, gfrc_image_outdir, 'gfrc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FN Z138_Img02888.jpg\n",
    "# FP Z247_Img14318.jpg\n",
    "# TP Z124_Img13083.jpg\n",
    "Image.open(gfrc_image_outdir + 'Z138_Img02888.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def create_mosaic(list_in, mosaic_tuple, image_size, multiplier=1, grey=False):\n",
    "    rowz = mosaic_tuple[0]\n",
    "    colz = mosaic_tuple[1]\n",
    "    img_rw = image_size[0] \n",
    "    img_cl = image_size[1] \n",
    "    img_asp =  img_rw / img_cl\n",
    "    channels = 3\n",
    "    if grey:\n",
    "        channels = 1\n",
    "    combined_im = np.zeros((img_rw * rowz * multiplier, img_cl * colz * multiplier, channels), dtype=np.uint8)\n",
    "    sample_list = random.sample(list_in, rowz*colz)\n",
    "    for idx, im in enumerate(sample_list):\n",
    "        im_shp = im.shape\n",
    "        im_rw = im_shp[0]\n",
    "        im_cl = im_shp[1]\n",
    "        im_asp = im_rw / im_cl\n",
    "        if im_asp > img_asp:\n",
    "            tot_cls = im_shp[0] / img_asp\n",
    "            ncls_to_add = int((tot_cls - im_shp[1]) / 2)\n",
    "            cls_to_add = np.ones((im_shp[0], ncls_to_add, 3)) * 255\n",
    "            border_im = np.hstack((cls_to_add, im, cls_to_add))\n",
    "        else:\n",
    "            tot_rws = im_shp[1] * img_asp\n",
    "            nrws_to_add = int((tot_rws - im_shp[0]) / 2)\n",
    "            rws_to_add = np.ones((nrws_to_add, im_shp[1], 3)) * 255\n",
    "            border_im = np.vstack((rws_to_add, im, rws_to_add))\n",
    "\n",
    "        im_reshape = cv2.resize(border_im, (img_cl * multiplier, img_rw * multiplier))\n",
    "        col = idx % colz\n",
    "        row = idx // colz\n",
    "        x1 = col * img_cl * multiplier\n",
    "        x2 = (col + 1) * img_cl * multiplier\n",
    "        y1 = row * img_rw * multiplier\n",
    "        y2 = (row + 1) * img_rw * multiplier\n",
    "        combined_im[y1:y2, x1:x2, :] = im_reshape\n",
    "        \n",
    "    return combined_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-international",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnz_combined = create_mosaic(gfrc_fnz, (4, 8), (60*2, 60*2))\n",
    "Image.fromarray(fnz_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpz_combined = create_mosaic(gfrc_fpz, (4, 8), (60*2, 60*2))\n",
    "Image.fromarray(fpz_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"/home/cmf21/pytorch_save/output_for_draft/\"\n",
    "outnam_g = 'gfrc_' + experiment + '_mosaic'\n",
    "fn_out_path = outdir + outnam_g + '_fn.jpg'\n",
    "fp_out_path = outdir + outnam_g + '_fp.jpg'\n",
    "fnz_combined = cv2.cvtColor(fnz_combined, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite(fn_out_path, fnz_combined)\n",
    "fpz_combined = cv2.cvtColor(fpz_combined, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite(fp_out_path, fpz_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def conf_mat_plot_heatmap(cm, display_labels, title_in, heatmap_type='true'):\n",
    "    fig, ax = plt.subplots(figsize=(6, 4.5))\n",
    "    n_classes = cm.shape[0]\n",
    "    cmap = 'Greys'\n",
    "\n",
    "    if heatmap_type == 'percent':\n",
    "        sum_vals = np.sum(cm)\n",
    "    elif heatmap_type == 'true':\n",
    "        sum_vals = np.reshape(np.repeat(np.sum(cm, axis=1), n_classes), (n_classes, n_classes))\n",
    "    elif heatmap_type == 'pred':\n",
    "        sum_vals = np.reshape(np.tile(np.sum(cm, axis=0), n_classes), (n_classes, n_classes))\n",
    "        print(sum_vals)\n",
    "\n",
    "    color_mapping = np.array(np.multiply(np.divide(cm, sum_vals), 255), np.uint8)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        for j in range(n_classes):\n",
    "            text_cm = format(cm[i, j], ',')\n",
    "            txt_color = [1, 1, 1] if color_mapping[i, j] > 100 else [0, 0, 0]\n",
    "            ax.text(j, i, text_cm, ha=\"center\", va=\"center\", color=txt_color, fontsize=18)\n",
    "            ax.axhline(i - .5, color='black', linewidth=1.0)\n",
    "            ax.axvline(j - .5, color='black', linewidth=1.0)\n",
    "\n",
    "    ax.matshow(color_mapping, cmap=cmap)\n",
    "\n",
    "    ax.set_xlabel(\"Predicted label\", fontsize=16)\n",
    "    ax.set_ylabel(\"True label\", fontsize=16)\n",
    "    ax.set_xticks(np.arange(n_classes))\n",
    "    ax.set_yticks(np.arange(n_classes))\n",
    "    ax.set_xticklabels(display_labels, fontsize=16)\n",
    "    ax.set_yticklabels(display_labels, fontsize=16)\n",
    "    ax.set_title(title_in, fontsize=16)\n",
    "    ax.tick_params(bottom=True, labelbottom=True, top=False, labeltop=False)\n",
    "\n",
    "    ax.set_ylim((n_classes - 0.5, -0.5))\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_mat_raw(true, predicted, labels):\n",
    "    mat_out = np.empty((len(labels), len(labels)))\n",
    "    for i, row in enumerate(labels):\n",
    "        preds_row = predicted[true == row]\n",
    "        for j, col in enumerate(labels):\n",
    "            mat_out[i, j] = np.sum(preds_row == col)\n",
    "    mat_out = np.array(mat_out, dtype=np.int)\n",
    "    return mat_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_conf_mat_plot(cm, labels, title, results_dir, prefix):\n",
    "    n_class = len(labels)\n",
    "    cm_all = np.reshape(np.array(cm, dtype=np.int), (n_class, n_class))\n",
    "    cm_out = conf_mat_plot_heatmap(cm_all, labels, title)\n",
    "    out_path = prefix + '_confidence_matrix.png'\n",
    "    results_dir = Path(results_dir)\n",
    "    cm_out.get_figure().savefig(results_dir / out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-terror",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfrc_results['tru_class_bin'] = np.array(gfrc_results.tru_class > 0, dtype=np.int)\n",
    "cm_gfrc = conf_mat_raw(gfrc_results.tru_class_bin, gfrc_results.pred_class, [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"/home/cmf21/pytorch_save/output_for_draft/\"\n",
    "title = \"GFRC binary confusion matrix \\n with hard negative mining\"\n",
    "labels = [\"none\", \"animal\"]\n",
    "affix = 'gfrc_' + experiment\n",
    "save_conf_mat_plot(cm_gfrc, labels, title, outdir, affix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
