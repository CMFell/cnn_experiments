{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from torchvision import transforms as transforms\n",
    "import torchvision.transforms.functional as tf\n",
    "\n",
    "from window.utils.tiling import create_tile_list, split_locations_array\n",
    "from window.models.yolo_for_inference import YoloClass\n",
    "from yolo.trch_yolonet import YoloNetMeta\n",
    "from window.utils.truths import windows_truth\n",
    "from window.utils.inference_windows import process_annotation_df_negative_inference, create_windows_from_yolo, windows_to_whole_im, xc_to_xmn\n",
    "from window.utils.drawing import draw_results_on_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-terrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_whole_image_dir = \"/data/old_home_dir/ChrissyF/GFRC/Test/whole_images/\"\n",
    "truth_file = \"/data/old_home_dir/ChrissyF/GFRC/Test/00_GFRC_bboxes.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_base_dir = \"/home/cmf21/pytorch_save/GFRC/Bin/meta_ci_end/\"\n",
    "nn = 149\n",
    "experiment = 'meta_ci_end'\n",
    "predict_results = False\n",
    "meta_end = True\n",
    "col_list = ['lowerci', 'upperci']\n",
    "\n",
    "#output_base_dir = \"/home/cmf21/pytorch_save/GFRC/Bin/rgb_baseline2/\"\n",
    "#nn = 163\n",
    "#experiment = 'rgb_baseline2'\n",
    "#predict_results = False\n",
    "#meta_end = False\n",
    "#col_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_object_loc = output_base_dir + 'boxes_out' + str(nn) + '_full.csv'\n",
    "saveweightspath = output_base_dir + \"testing_save_\" + str(nn) + \".pt\"\n",
    "channels_in = 3\n",
    "nclazz = 1\n",
    "dataset = 'gfrc'\n",
    "channels_in = channels_in + len(col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = output_base_dir + \"test_images_out/\"\n",
    "output_csv = output_dir + \"test_results/results_matched_nms.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files_jpg = list(Path(valid_whole_image_dir).glob(\"*.jpg\"))\n",
    "image_files_png = list(Path(valid_whole_image_dir).glob(\"*.png\"))\n",
    "image_files = image_files_jpg + image_files_png\n",
    "image_files = [img.name for img in image_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process truth files\n",
    "truths = pd.read_csv(truth_file)\n",
    "\n",
    "truths.loc[:, 'filename'] = [strin.replace('/', '_') for strin in truths.file_loc]\n",
    "truths = windows_truth(truths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "truths['oc'] = 0\n",
    "truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_filename(str_in):\n",
    "    file_nm = str_in[:-4]\n",
    "    file_splt = file_nm.split('_')\n",
    "    file_out = file_splt[0] + '_' + file_splt[1] + '.jpg'\n",
    "    tile_out = file_splt[2]\n",
    "    return file_out, tile_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "if predict_results:\n",
    "    yolo_model = YoloClass(wtpath=saveweightspath, channels=channels_in, nclazz=nclazz, meta_cols=col_list, meta_end=meta_end)\n",
    "        \n",
    "    windows_whole = pd.DataFrame(columns=['xc', 'yc', 'wid', 'hei', 'conf', 'class', 'xmn', 'xmx', 'ymn', 'ymx', 'filename'])\n",
    "\n",
    "    for idx, fl in enumerate(image_files):\n",
    "        # Per image\n",
    "        print(fl, idx, \"of 317\")\n",
    "        \n",
    "        whole_im = io.imread(valid_whole_image_dir + fl, as_gray=False)\n",
    "\n",
    "        orig_im_size = whole_im.shape\n",
    "        \n",
    "        # create tiles\n",
    "        tilez = create_tile_list(whole_im)\n",
    "\n",
    "        # get predictions from yolo\n",
    "        boxes_whole_im = yolo_model.inference_on_image(tilez, 0.005, fl)\n",
    "\n",
    "        windows_whole_im = windows_to_whole_im(boxes_whole_im)\n",
    "        \n",
    "        windows_whole_im['filename'] = fl\n",
    "\n",
    "        windows_whole = pd.concat((windows_whole, windows_whole_im), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = pd.read_csv('/home/cmf21/pytorch_save/GFRC/preds_for_cnn.csv')\n",
    "image_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-biography",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-resolution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "if predict_results:\n",
    "    windows_whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/home/cmf21/pytorch_save/output_for_draft/\"\n",
    "windows_filename = experiment + '_test_windows.csv'\n",
    "if predict_results:    \n",
    "    windows_part = windows_whole[windows_whole.conf > 0.01]\n",
    "    windows_part.to_csv(output_dir + windows_filename, index=False)\n",
    "else:\n",
    "    windows_whole = pd.read_csv(output_dir + windows_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_truths(truths, dataset):\n",
    "    truths.loc[:, 'filename'] = [strin.replace('/', '_') for strin in truths.file_loc]\n",
    "    truths = windows_truth(truths)\n",
    "    truths['oc'] = truths['oc'].add(1)\n",
    "    truths['tru_class'] = truths['oc']\n",
    "    return truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfrc_truth = pd.read_csv(truth_file)\n",
    "gfrc_truth = process_truths(gfrc_truth, 'gfrc')\n",
    "gfrc_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-camping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find biggest and smallest truth\n",
    "print(max(np.max(gfrc_truth.xmx - gfrc_truth.xmn), np.max(gfrc_truth.ymx - gfrc_truth.ymn)))\n",
    "print(min(np.min(gfrc_truth.xmx - gfrc_truth.xmn), np.min(gfrc_truth.ymx - gfrc_truth.ymn)))\n",
    "# find biggest and smallest area\n",
    "print(np.max((gfrc_truth.xmx - gfrc_truth.xmn) * (gfrc_truth.ymx - gfrc_truth.ymn)))\n",
    "print(np.min((gfrc_truth.xmx - gfrc_truth.xmn) * (gfrc_truth.ymx - gfrc_truth.ymn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "too_small = int(0.75*11)\n",
    "too_big = int(1.25*163)\n",
    "area_too_small = int(0.75*319)\n",
    "area_too_big = int(1.25*24287)\n",
    "print(too_small, too_big, area_too_small, area_too_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-witness",
   "metadata": {},
   "outputs": [],
   "source": [
    "if predict_results:\n",
    "    gfrc_windows_in = windows_whole\n",
    "else:\n",
    "    gfrc_windows_in = pd.read_csv(output_dir + windows_filename)\n",
    "gfrc_windows_in.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gfrc_windows_in = pd.read_csv(predicted_object_loc)\n",
    "#filez = np.unique(gfrc_windows_in.file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_dir = \"/home/cmf21/pytorch_save/output_for_draft/\"\n",
    "#windows_filename = experiment + '_test_windows.csv'\n",
    "#gfrc_windows_in = pd.read_csv(output_dir + windows_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-advancement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-madonna",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove too big and too small detections\n",
    "gfrc_windows = gfrc_windows_in\n",
    "gfrc_windows['xside'] = gfrc_windows.xmx - gfrc_windows.xmn\n",
    "gfrc_windows['yside'] = gfrc_windows.ymx - gfrc_windows.ymn\n",
    "gfrc_windows['minside'] = np.minimum(gfrc_windows.xside, gfrc_windows.yside)\n",
    "gfrc_windows['maxside'] = np.maximum(gfrc_windows.xside, gfrc_windows.yside)\n",
    "gfrc_windows['area'] = gfrc_windows.xside * gfrc_windows.yside\n",
    "print(np.max(gfrc_windows.maxside), np.min(gfrc_windows.minside))\n",
    "gfrc_windows = gfrc_windows[gfrc_windows.minside > too_small]\n",
    "gfrc_windows = gfrc_windows[gfrc_windows.maxside < too_big]\n",
    "gfrc_windows = gfrc_windows[gfrc_windows.area < area_too_big]\n",
    "gfrc_windows = gfrc_windows[gfrc_windows.area > area_too_small]\n",
    "gfrc_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfrc_windows[gfrc_windows.yside == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms_per_im(boxes_in, thresh, method='mean'):\n",
    "    \n",
    "    boxes_in = boxes_in.sort_values(by='conf', ascending=False)\n",
    "\n",
    "    xmins = boxes_in.xmn\n",
    "    xmaxs = boxes_in.xmx\n",
    "    ymins = boxes_in.ymn\n",
    "    ymaxs = boxes_in.ymx\n",
    "    confs = boxes_in.conf\n",
    "    clazs = boxes_in['class']\n",
    "\n",
    "    boxes_ot = pd.DataFrame(columns=['xmn', 'xmx', 'ymn', 'ymx', 'conf', 'pred_class'])\n",
    "\n",
    "    xmins = np.array(xmins.tolist())\n",
    "    xmaxs = np.array(xmaxs.tolist())\n",
    "    ymins = np.array(ymins.tolist())\n",
    "    ymaxs = np.array(ymaxs.tolist())\n",
    "    confs = np.array(confs.tolist())\n",
    "    clazs = np.array(clazs.tolist())\n",
    "\n",
    "    while len(xmins) > 0:\n",
    "\n",
    "        xmn = xmins[0]\n",
    "        xmns = np.array(xmins[1:])\n",
    "        xmx = xmaxs[0]\n",
    "        xmxs = np.array(xmaxs[1:])\n",
    "        ymn = ymins[0]\n",
    "        ymns = np.array(ymins[1:])\n",
    "        ymx = ymaxs[0]\n",
    "        ymxs = np.array(ymaxs[1:])\n",
    "        cnf = confs[0]\n",
    "        cnfs = np.array(confs[1:])\n",
    "        clz = clazs[0]\n",
    "        clzs = np.array(clazs[1:])\n",
    "\n",
    "        ol_wid = np.minimum(xmx, xmxs) - np.maximum(xmn, xmns)\n",
    "        ol_hei = np.minimum(ymx, ymxs) - np.maximum(ymn, ymns)\n",
    "\n",
    "        ol_x = np.maximum(0, ol_wid)\n",
    "        ol_y = np.maximum(0, ol_hei)\n",
    "\n",
    "        distx = np.subtract(xmxs, xmns)\n",
    "        disty = np.subtract(ymxs, ymns)\n",
    "        bxx = xmx - xmn\n",
    "        bxy = ymx - ymn\n",
    "\n",
    "        ol_area = np.multiply(ol_x, ol_y)\n",
    "        bx_area = bxx * bxy\n",
    "        bxs_area = np.multiply(distx, disty)\n",
    "\n",
    "        ious = np.divide(ol_area, np.subtract(np.add(bxs_area, bx_area), ol_area))\n",
    "        mask_bxs = np.greater(ious, thresh)\n",
    "\n",
    "        if np.sum(mask_bxs) > 0:\n",
    "            box_ot = pd.DataFrame(index=range(1), columns=['xmn', 'xmx', 'ymn', 'ymx', 'conf', 'pred_class'])\n",
    "\n",
    "            xmns = xmns[mask_bxs]\n",
    "            xmxs = xmxs[mask_bxs]\n",
    "            ymns = ymns[mask_bxs]\n",
    "            ymxs = ymxs[mask_bxs]\n",
    "            cnfs = cnfs[mask_bxs]\n",
    "\n",
    "            if method == 'mean':\n",
    "                box_ot.loc[0, 'xmn'] = np.array(np.mean(xmns), dtype=int)\n",
    "                box_ot.loc[0, 'ymn'] = np.array(np.mean(ymns), dtype=int)\n",
    "                box_ot.loc[0, 'xmx'] = np.array(np.mean(xmxs), dtype=int)\n",
    "                box_ot.loc[0, 'ymx'] = np.array(np.mean(ymxs), dtype=int)\n",
    "                box_ot.loc[0, 'conf'] = np.mean(cnfs)\n",
    "                box_ot.loc[0, 'pred_class'] = clz\n",
    "            elif method == 'first':\n",
    "                box_ot.loc[0, 'xmn'] = xmns[0]\n",
    "                box_ot.loc[0, 'ymn'] = ymns[0]\n",
    "                box_ot.loc[0, 'xmx'] = xmxs[0]\n",
    "                box_ot.loc[0, 'ymx'] = ymxs[0]\n",
    "                box_ot.loc[0, 'conf'] = np.max(cnfs)\n",
    "                box_ot.loc[0, 'pred_class'] = clz\n",
    "            else:\n",
    "                box_ot.loc[0, 'xmn'] = np.min(xmns)\n",
    "                box_ot.loc[0, 'ymn'] = np.min(ymns)\n",
    "                box_ot.loc[0, 'xmx'] = np.max(xmxs)\n",
    "                box_ot.loc[0, 'ymx'] = np.max(ymxs)\n",
    "                box_ot.loc[0, 'conf'] = np.max(cnfs)\n",
    "                box_ot.loc[0, 'pred_class'] = clz\n",
    "\n",
    "            mask_out = np.repeat(False, len(xmins))\n",
    "            mask_out[0] = True\n",
    "            mask_out[1:] = mask_bxs\n",
    "            mask_out = np.logical_not(mask_out)\n",
    "\n",
    "            xmins = xmins[mask_out]\n",
    "            xmaxs = xmaxs[mask_out]\n",
    "            ymins = ymins[mask_out]\n",
    "            ymaxs = ymaxs[mask_out]\n",
    "            confs = confs[mask_out]\n",
    "            clazs = clazs[mask_out]\n",
    "            \n",
    "        else:\n",
    "            box_ot = pd.DataFrame(index=range(1), columns=['xmn', 'xmx', 'ymn', 'ymx', 'conf', 'pred_class'])\n",
    "\n",
    "            box_ot.loc[0, 'xmn'] = xmn\n",
    "            box_ot.loc[0, 'ymn'] = ymn\n",
    "            box_ot.loc[0, 'xmx'] = xmx\n",
    "            box_ot.loc[0, 'ymx'] = ymx\n",
    "            box_ot.loc[0, 'conf'] = cnf\n",
    "            box_ot.loc[0, 'pred_class'] = clz\n",
    "\n",
    "            mask_out = np.repeat(False, len(xmins))\n",
    "            mask_out[0] = True\n",
    "            mask_out = np.logical_not(mask_out)\n",
    "            \n",
    "            xmins = xmins[mask_out]\n",
    "            xmaxs = xmaxs[mask_out]\n",
    "            ymins = ymins[mask_out]\n",
    "            ymaxs = ymaxs[mask_out]\n",
    "            confs = confs[mask_out]\n",
    "            clazs = clazs[mask_out]\n",
    "            \n",
    "        #box_ot = box_ot.reset_index(drop=True)\n",
    "        boxes_ot = pd.concat((boxes_ot, box_ot), axis=0, sort=False)\n",
    "\n",
    "    boxes_ot.loc[:, 'filename'] = boxes_in.filename.iloc[0]\n",
    "\n",
    "    return boxes_ot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-diamond",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms_for_yolo(windows_df, nms_thresh, method):\n",
    "    images = np.unique(windows_df.filename)\n",
    "    windows_all_ims = pd.DataFrame(columns=['xmn', 'xmx', 'ymn', 'ymx', 'conf', 'pred_class', 'filename'])\n",
    "    for im in images:\n",
    "        windows_im = windows_df[windows_df.filename == im]\n",
    "        windows_im = nms_per_im(windows_im, nms_thresh, method)\n",
    "        windows_all_ims.append(windows_im)\n",
    "        windows_all_ims = pd.concat((windows_all_ims, windows_im), axis=0, ignore_index=True, sort=False)\n",
    "    return windows_all_ims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-transmission",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(box1, box2):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xa = max(box1.xmn, box2.xmn)\n",
    "    xb = min(box1.xmx, box2.xmx)\n",
    "    ya = max(box1.ymn, box2.ymn)\n",
    "    yb = min(box1.ymx, box2.ymx)\n",
    "    # compute the area of intersection rectangle\n",
    "    inter_area = max(0, xb - xa + 1) * max(0, yb - ya + 1)\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    box1_area = (box1.xmx - box1.xmn + 1) * (box1.ymx - box1.ymn + 1)\n",
    "    box2_area = (box2.xmx - box2.xmn + 1) * (box2.ymx - box2.ymn + 1)\n",
    "    # compute the intersection over union \n",
    "    iou = inter_area / float(box1_area + box2_area - inter_area)\n",
    "    # return the intersection over union value\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_to_truth_im(detections_df, truth_df, iou_threshold):\n",
    "    \n",
    "    if detections_df.shape[0] > 0:\n",
    "        results_out = pd.DataFrame(columns = ['xmn', 'xmx', 'ymn', 'ymx', 'conf', 'filename', 'pred_class', \n",
    "                                              'tru_class'])\n",
    "        results_per_im = detections_df[['xmn', 'xmx', 'ymn', 'ymx', 'conf', 'filename', 'pred_class']]\n",
    "        results_per_im = results_per_im.reset_index(drop=True)\n",
    "        truths_per_im = truth_df.reset_index(drop=True)\n",
    "        # best match stores the detection with the highest iou\n",
    "        best_match = [False] * results_per_im.shape[0]\n",
    "        # true match stores if the truth overlaps with any detections\n",
    "        true_match = [False] * truth_df.shape[0]\n",
    "        # matchz stores any matches that overlap but aren't the best overlap (not double counting TP, but not adding to FP)\n",
    "        matchz = np.array([True] * results_per_im.shape[0])\n",
    "\n",
    "        for idx, tru in truths_per_im.iterrows():\n",
    "            iouz = []\n",
    "            for res_idx, result in results_per_im.iterrows():\n",
    "                iou = intersection_over_union(tru, result)\n",
    "                iouz.append(iou)\n",
    "            iou_ind = np.argmax(iouz)\n",
    "            if iouz[iou_ind] > iou_threshold:\n",
    "                if not best_match[iou_ind]: \n",
    "                    best_iou_res = results_per_im.iloc[iou_ind:(iou_ind+1), :]\n",
    "                    best_iou_res = best_iou_res.reset_index(drop=True)\n",
    "                    best_iou_res.loc[:, 'confmat'] = 'TP'\n",
    "                    true_box = f'xmin: {tru.xmn}; xmax:{tru.xmx}; ymin: {tru.ymn}; ymax: {tru.ymx}'\n",
    "                    best_iou_res.loc[:, 'tru_box'] = true_box\n",
    "                    best_iou_res.loc[:, 'tru_class'] = tru.tru_class\n",
    "                    results_out = pd.concat((results_out, best_iou_res), axis=0, ignore_index=True, sort=False)\n",
    "                    best_match[iou_ind] = True\n",
    "                    true_match[idx] = True\n",
    "            # matchz removes any matches that overlap but are not the most overlapping\n",
    "            match_mask = np.array(iouz) > iou_threshold\n",
    "            matchz[match_mask] = False\n",
    "\n",
    "        # use matchz to filter results to keep only those that don't overlap with truths\n",
    "        results_per_im = results_per_im[matchz]\n",
    "        results_per_im = results_per_im.reset_index(drop=True)\n",
    "\n",
    "        if results_per_im.shape[0] > 0:\n",
    "            results_per_im['confmat'] = 'FP'\n",
    "            results_per_im['tru_box'] = ''\n",
    "            results_per_im['tru_class'] = 0\n",
    "        results_out = pd.concat((results_out, results_per_im), axis=0, ignore_index=True, sort=False)  \n",
    "        true_match = np.array(true_match)\n",
    "        true_match = np.logical_not(true_match)\n",
    "        if np.sum(true_match) > 0:\n",
    "            false_negatives = truth_df[['xmn', 'xmx', 'ymn', 'ymx', 'filename', 'tru_class']]\n",
    "            false_negatives = false_negatives[true_match]\n",
    "            false_negatives = false_negatives.reset_index(drop=True)\n",
    "            false_negatives.loc[:, 'conf'] = 1.0\n",
    "            false_negatives.loc[:, 'confmat'] = 'FN'\n",
    "            false_negatives.loc[:, 'tru_box'] = ''\n",
    "            false_negatives.loc[:, 'pred_class'] = 0\n",
    "            results_out = pd.concat((results_out, false_negatives), axis=0, ignore_index=True, sort=False)\n",
    "        results_out = results_out.reset_index(drop=True)\n",
    "    else:\n",
    "        results_out = truth_df.loc[:, ['xmn', 'xmx', 'ymn', 'ymx', 'filename', 'tru_class']]\n",
    "        results_out.columns = ['xmn', 'xmx', 'ymn', 'ymx', 'filename', 'tru_class']\n",
    "        results_out.loc[:, 'conf'] = 1\n",
    "        results_out.loc[:, 'confmat'] = 'FN'\n",
    "        results_out.loc[:, 'tru_box'] = ''\n",
    "        results_out.loc[:, 'pred_class'] = 0\n",
    "\n",
    "    return results_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-annex",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_to_truth(detections_df, truth_df, valid_whole_image_dir, iou_threshold):\n",
    "    image_files_jpg = list(Path(valid_whole_image_dir).glob(\"*.jpg\"))\n",
    "    image_files_png = list(Path(valid_whole_image_dir).glob(\"*.png\"))\n",
    "    image_files = image_files_jpg + image_files_png\n",
    "    image_files = [img.name for img in image_files]\n",
    "    matched_results = pd.DataFrame(columns=['xmn', 'xmx', 'ymn', 'ymx', 'conf', 'filename', 'confmat', 'tru_box', 'pred_class', 'tru_class'])\n",
    "    \n",
    "    for im in image_files:\n",
    "        detections_im = detections_df[detections_df.filename == im]\n",
    "        truth_im = truth_df[truth_df.filename == im]\n",
    "        if detections_im.shape[0] > 0:\n",
    "            # detections and truths need to match\n",
    "            if truth_im.shape[0] > 0:\n",
    "                match_results_im = match_to_truth_im(detections_im, truth_im, iou_threshold)\n",
    "            # detections and no truths - all detections false postive\n",
    "            else:\n",
    "                match_results_im = detections_im[['xmn', 'xmx', 'ymn', 'ymx', 'conf', 'filename', 'pred_class']]\n",
    "                match_results_im['confmat'] = 'FP'\n",
    "                match_results_im['tru_box'] = ''\n",
    "                match_results_im['tru_class'] = 0\n",
    "        else:\n",
    "            # no detections and truths - all truths false negatives\n",
    "            if truth_im.shape[0] > 0:\n",
    "                match_results_im = truth_im[['xmn', 'xmx', 'ymn', 'ymx', 'filename', 'tru_class']]\n",
    "                match_results_im['conf'] = 1.0\n",
    "                match_results_im['confmat'] = 'FN'\n",
    "                match_results_im['tru_box'] = ''\n",
    "                match_results_im['pred_class'] = 0\n",
    "            else:\n",
    "                match_results_im = pd.DataFrame(columns=['xmn', 'xmx', 'ymn', 'ymx', 'conf', 'filename', 'confmat', 'tru_box', 'pred_class', 'tru_class'])\n",
    "        matched_results = pd.concat((matched_results, match_results_im), axis=0, ignore_index=True, sort=False)\n",
    "    \n",
    "    return matched_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_threshold_results(windows_df, truth_df, im_dir, nms_threshold=0.05, iou_threshold=0.25, method='first', start_thresh=0.01, nsteps=100):\n",
    "    threshes = np.linspace(start_thresh, 1, nsteps)\n",
    "    threshold_array = np.zeros((len(threshes), 8))\n",
    "    image_files_jpg = list(Path(im_dir).glob(\"*.jpg\"))\n",
    "    image_files_png = list(Path(im_dir).glob(\"*.png\"))\n",
    "    image_files = image_files_jpg + image_files_png\n",
    "    image_files = [img.name for img in image_files]\n",
    "    for idx, th in enumerate(threshes):\n",
    "        print(th)\n",
    "        detections_th = windows_df[windows_df.conf > th]\n",
    "        detections_th = nms_for_yolo(detections_th, nms_threshold, method)\n",
    "        result_th = match_to_truth(detections_th, truth_df, im_dir, iou_threshold)\n",
    "        TP = np.sum(result_th.confmat==\"TP\")\n",
    "        FP = np.sum(result_th.confmat==\"FP\")\n",
    "        FN = np.sum(result_th.confmat==\"FN\")\n",
    "        RE = TP / (TP + FN)\n",
    "        PR = TP / (TP + FP)\n",
    "        MR = 1 - RE\n",
    "        FPPI = FP / len(image_files)\n",
    "\n",
    "        list_out = [th, TP, FP, FN, RE, PR, MR, FPPI]\n",
    "\n",
    "        threshold_array[idx, :] = list_out \n",
    "        \n",
    "    threshold_metrics = pd.DataFrame(threshold_array, columns=['threshold', 'TP', 'FP', 'FN', 'RE', 'PR', 'MR', 'FPPI'])\n",
    "    return threshold_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-weather",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "if predict_results:\n",
    "    gfrc_metrics = calculate_threshold_results(gfrc_windows, gfrc_truth, valid_whole_image_dir, 0.25, 0.25, 'mean', 0.05, 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "if predict_results:\n",
    "    gfrc_metrics.to_csv(output_dir + 'gfrc_' + experiment + \"_test_metrics.csv\", index=False)\n",
    "else:\n",
    "    gfrc_metrics = pd.read_csv(output_dir + 'gfrc_' + experiment + \"_test_metrics.csv\")\n",
    "gfrc_metrics[gfrc_metrics.RE > 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if experiment == 'rgb_baseline2':\n",
    "    gfrc_conf_threshold = 0.2 #rgb baseline final\n",
    "else:\n",
    "    gfrc_conf_threshold = 0.25 #ci?\n",
    "gfrc_metrics[gfrc_metrics.RE > 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-china",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfrc_conf_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_threshold_results(windows_df, truth_df, im_dir, thresh, nms_threshold=0.05, iou_threshold=0.25, method='first'):\n",
    "\n",
    "    image_files_jpg = list(Path(im_dir).glob(\"*.jpg\"))\n",
    "    image_files_png = list(Path(im_dir).glob(\"*.png\"))\n",
    "    image_files = image_files_jpg + image_files_png\n",
    "    image_files = [img.name for img in image_files]\n",
    "    detections_th = windows_df[windows_df.conf > thresh]\n",
    "    detections_th['class'] = detections_th['class'].add(1)\n",
    "    detections_th = nms_for_yolo(detections_th, nms_threshold, method)\n",
    "    result_th = match_to_truth(detections_th, truth_df, im_dir, iou_threshold)\n",
    "\n",
    "    return result_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "if predict_results:\n",
    "    gfrc_results = single_threshold_results(gfrc_windows, gfrc_truth, valid_whole_image_dir, gfrc_conf_threshold, 0.25, 0.25, 'mean')\n",
    "    gfrc_results.to_csv(output_dir + 'gfrc_' + experiment + \"_test_results.csv\", index=False)\n",
    "else:\n",
    "    gfrc_results = pd.read_csv(output_dir + 'gfrc_' + experiment + \"_test_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-secret",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(gfrc_results.confmat == \"TP\"), np.sum(gfrc_results.confmat == \"FP\")/316)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gfrc_results_rgb = pd.read_csv(output_dir + \"gfrc_gfrc_rgb_bin_results.csv\")\n",
    "#print(np.sum(gfrc_results_rgb.confmat == \"TP\"), np.sum(gfrc_results_rgb.confmat == \"FP\")/316)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_stats(detections_df):\n",
    "    unique_images = np.unique(detections_df.filename)\n",
    "    tpz = []\n",
    "    fpz = []\n",
    "    fnz = []\n",
    "    for fl in unique_images:\n",
    "        results_per_im = detections_df[detections_df['filename'] == fl]\n",
    "        tpz.append(np.sum(results_per_im.confmat == 'TP'))\n",
    "        fpz.append(np.sum(results_per_im.confmat == 'FP'))\n",
    "        fnz.append(np.sum(results_per_im.confmat == 'FN'))\n",
    "\n",
    "    TPz = np.reshape(np.array(tpz), (len(tpz), 1))\n",
    "    FPz = np.reshape(np.array(fpz), (len(fpz), 1))\n",
    "    FNz = np.reshape(np.array(fnz), (len(fnz), 1))\n",
    "    UIz = np.reshape(unique_images, (len(unique_images), 1))\n",
    "    df_out = pd.DataFrame(np.hstack((UIz, TPz, FPz, FNz)), columns=['filename', 'TP', 'FP', 'FN'])\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-hamburg",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-style",
   "metadata": {},
   "outputs": [],
   "source": [
    "if predict_results:\n",
    "    gfrc_image_results = get_image_stats(gfrc_results)\n",
    "    gfrc_image_results.to_csv(output_dir + 'gfrc_' + experiment + \"_test_image_results.csv\", index=False)\n",
    "else:\n",
    "    gfrc_image_results = pd.read_csv(output_dir + 'gfrc_' + experiment + \"_test_image_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-voice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_res(results_all_ims, valid_whole_image_dir, image_out_dir, dataset, experiment):\n",
    "    \n",
    "    Path(image_out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    image_files_jpg = list(Path(valid_whole_image_dir).glob(\"*.jpg\"))\n",
    "    image_files_png = list(Path(valid_whole_image_dir).glob(\"*.png\"))\n",
    "    image_files = image_files_jpg + image_files_png\n",
    "    image_files = [img.name for img in image_files]\n",
    "\n",
    "    for fl in image_files:\n",
    "        # Per image\n",
    "        whole_im = cv2.imread(valid_whole_image_dir + fl)\n",
    "        whole_im = cv2.cvtColor(whole_im, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        fl_png = fl\n",
    "\n",
    "        # calculate results\n",
    "        results_per_im = results_all_ims[results_all_ims.filename == fl]\n",
    "\n",
    "        # draw results on image\n",
    "        image_out = draw_results_on_image(whole_im, results_per_im)\n",
    "        #image_out = cv2.resize(image_out, (1840, 1228))\n",
    "        image_out = cv2.cvtColor(image_out, cv2.COLOR_BGR2RGB)\n",
    "        im_name = fl[:-4] + '_' + experiment + fl[-4:]\n",
    "        cv2.imwrite(str(image_out_dir + im_name), image_out)\n",
    "        cv2.imwrite(str(image_out_dir + fl), image_out)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-permission",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-trademark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fpz(results_all_ims, valid_whole_image_dir, image_out_dir, dataset, experiment):\n",
    "\n",
    "    fpz_out = []\n",
    "    \n",
    "    Path(image_out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    fn_images = results_all_ims[results_all_ims.confmat=='FP']\n",
    "    \n",
    "    image_files = np.unique(fn_images.filename).tolist()\n",
    "    image_files = [Path(fl) for fl in image_files]\n",
    "    image_files = [img.name for img in image_files]\n",
    "\n",
    "    for fl in image_files:\n",
    "        # Per image\n",
    "        whole_im = cv2.imread(valid_whole_image_dir + fl)\n",
    "        whole_im = cv2.cvtColor(whole_im, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        fl_png = fl\n",
    "\n",
    "        # calculate results\n",
    "        results_per_im = results_all_ims[results_all_ims.filename == fl]\n",
    "\n",
    "        # create list of all false negatives\n",
    "        for rw in range(results_per_im.shape[0]):\n",
    "            row = results_per_im.iloc[rw, :]\n",
    "            if row.confmat == 'FP':\n",
    "                xmn = max(0, row.xmn - 50)\n",
    "                ymn = max(0, row.ymn - 50)\n",
    "                xmx = min(whole_im.shape[1], row.xmx + 50)\n",
    "                ymx = min(whole_im.shape[0], row.ymx + 50)\n",
    "                fp_window = whole_im[row.ymn:row.ymx, row.xmn:row.xmx]\n",
    "                f_window = cv2.resize(fp_window, (fp_window.shape[1]*2, fp_window.shape[0]*2))\n",
    "                fpz_out.append(fp_window)\n",
    "        \n",
    "    return fpz_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fnz(results_all_ims, valid_whole_image_dir, image_out_dir, dataset, experiment):\n",
    "\n",
    "    fnz_out = []\n",
    "    \n",
    "    Path(image_out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    fn_images = results_all_ims[results_all_ims.confmat=='FN']\n",
    "    \n",
    "    image_files = np.unique(fn_images.filename).tolist()\n",
    "    image_files = [Path(fl) for fl in image_files]\n",
    "    image_files = [img.name for img in image_files]\n",
    "\n",
    "    for fl in image_files:\n",
    "        # Per image\n",
    "        whole_im = cv2.imread(valid_whole_image_dir + fl)\n",
    "        whole_im = cv2.cvtColor(whole_im, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        fl_png = fl\n",
    "\n",
    "        # calculate results\n",
    "        results_per_im = results_all_ims[results_all_ims.filename == fl]\n",
    "\n",
    "        # create list of all false negatives\n",
    "        for rw in range(results_per_im.shape[0]):\n",
    "            row = results_per_im.iloc[rw, :]\n",
    "            if row.confmat == 'FN':\n",
    "                xmn = max(0, row.xmn - 50)\n",
    "                ymn = max(0, row.ymn - 50)\n",
    "                xmx = min(whole_im.shape[1], row.xmx + 50)\n",
    "                ymx = min(whole_im.shape[0], row.ymx + 50)\n",
    "                fn_window = whole_im[row.ymn:row.ymx, row.xmn:row.xmx]\n",
    "                fn_window = cv2.resize(fn_window, (fn_window.shape[1]*2, fn_window.shape[0]*2))\n",
    "                fnz_out.append(fn_window)\n",
    "        \n",
    "    return fnz_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfrc_image_outdir = \"/home/cmf21/pytorch_save/output_for_draft/\" + 'gfrc_' + experiment + '_25_25/'\n",
    "draw_dir = \"/home/cmf21/pytorch_save/output_for_draft/images_to_draw_test/\"\n",
    "Path(gfrc_image_outdir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-imagination",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_res(gfrc_results, draw_dir + 'GFRC/', gfrc_image_outdir, 'gfrc', experiment)\n",
    "gfrc_fnz = get_fnz(gfrc_results, valid_whole_image_dir, gfrc_image_outdir, 'gfrc', experiment)\n",
    "gfrc_fpz = get_fpz(gfrc_results, valid_whole_image_dir, gfrc_image_outdir, 'gfrc', experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfrc_image_results[gfrc_image_results.TP > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfrc_image_results['recall'] = gfrc_image_results['TP'] / (gfrc_image_results['TP'] + gfrc_image_results['FN'] + 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfrc_image_results[gfrc_image_results.FP>20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gfrc_image_results[gfrc_image_results.filename == 'Z81_Img06976.jpg'])\n",
    "Image.open(gfrc_image_outdir + 'Z81_Img06976_' + experiment + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\"/home/cmf21/pytorch_save/output_for_draft/\" + 'gfrc_rgb_baseline2_25_25/' + 'Z81_Img06976_rgb_baseline2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gfrc_image_results[gfrc_image_results.filename == 'Z108_Img00684.jpg'])\n",
    "Image.open(gfrc_image_outdir + 'Z108_Img00684_' + experiment + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gfrc_image_results[gfrc_image_results.filename == 'Z110_Img02292.jpg'])\n",
    "Image.open(gfrc_image_outdir + 'Z110_Img02292_' + experiment + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gfrc_image_results[gfrc_image_results.filename == 'Z123_Img12080.jpg'])\n",
    "Image.open(gfrc_image_outdir + 'Z123_Img12080_' + experiment + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfrc_image_results_rgb = pd.read_csv(\"/home/cmf21/pytorch_save/output_for_draft/\" + 'gfrc_' + 'rgb_baseline2' + \"_test_image_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfrc_image_results_rgb[gfrc_image_results_rgb.TP>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-tunnel",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfrc_image_results[gfrc_image_results.TP>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_funk(df):\n",
    "    FP0 = np.sum(df.FP == 0)\n",
    "    FP1 = np.sum(np.logical_and(df.FP > 0, df.FP < 6))\n",
    "    FP5 = np.sum(np.logical_and(df.FP > 5, df.FP < 11))\n",
    "    FP10 = np.sum(np.logical_and(df.FP > 10, df.FP < 21))\n",
    "    FP20 = np.sum(np.logical_and(df.FP > 20, df.FP < 51))\n",
    "    FP50 = np.sum(df.FP > 50)\n",
    "    return (FP0, FP1, FP5, FP10, FP20, FP50)\n",
    "\n",
    "count_funk(gfrc_image_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_funk(gfrc_image_results_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfrc_image_results_val = pd.read_csv(\"/home/cmf21/pytorch_save/output_for_draft/\" + 'gfrc_' + experiment + \"_image_results.csv\")\n",
    "count_funk(gfrc_image_results_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-exclusive",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-digest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# final\n",
    "# FN Z138_Img02888.jpg\n",
    "# FP Z120_Img11234.jpg\n",
    "# TP Z124_Img13083.jpg\n",
    "Image.open(gfrc_image_outdir + 'Z138_Img02888_' + experiment + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-underwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_mosaic(list_in, mosaic_tuple, image_size, multiplier=1, grey=False):\n",
    "    rowz = mosaic_tuple[0]\n",
    "    colz = mosaic_tuple[1]\n",
    "    img_rw = image_size[0] \n",
    "    img_cl = image_size[1] \n",
    "    img_asp =  img_rw / img_cl\n",
    "    channels = 3\n",
    "    if grey:\n",
    "        channels = 1\n",
    "    combined_im = np.zeros((img_rw * rowz * multiplier, img_cl * colz * multiplier, channels), dtype=np.uint8)\n",
    "    sample_list = random.sample(list_in, rowz*colz)\n",
    "    for idx, im in enumerate(sample_list):\n",
    "        im_shp = im.shape\n",
    "        im_rw = im_shp[0]\n",
    "        im_cl = im_shp[1]\n",
    "        im_asp = im_rw / im_cl\n",
    "        if im_asp > img_asp:\n",
    "            tot_cls = im_shp[0] / img_asp\n",
    "            ncls_to_add = int((tot_cls - im_shp[1]) / 2)\n",
    "            cls_to_add = np.ones((im_shp[0], ncls_to_add, 3)) * 255\n",
    "            border_im = np.hstack((cls_to_add, im, cls_to_add))\n",
    "        else:\n",
    "            tot_rws = im_shp[1] * img_asp\n",
    "            nrws_to_add = int((tot_rws - im_shp[0]) / 2)\n",
    "            rws_to_add = np.ones((nrws_to_add, im_shp[1], 3)) * 255\n",
    "            border_im = np.vstack((rws_to_add, im, rws_to_add))\n",
    "\n",
    "        im_reshape = cv2.resize(border_im, (img_cl * multiplier, img_rw * multiplier))\n",
    "        col = idx % colz\n",
    "        row = idx // colz\n",
    "        x1 = col * img_cl * multiplier\n",
    "        x2 = (col + 1) * img_cl * multiplier\n",
    "        y1 = row * img_rw * multiplier\n",
    "        y2 = (row + 1) * img_rw * multiplier\n",
    "        combined_im[y1:y2, x1:x2, :] = im_reshape\n",
    "        \n",
    "    return combined_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-tulsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gfrc_fnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnz_combined = create_mosaic(gfrc_fnz, (4, 8), (60*2, 60*2))\n",
    "Image.fromarray(fnz_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpz_combined = create_mosaic(gfrc_fpz, (4, 8), (60*2, 60*2))\n",
    "Image.fromarray(fpz_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"/home/cmf21/pytorch_save/output_for_draft/\"\n",
    "outnam_g = 'gfrc_' + experiment + 'test_mosaic'\n",
    "fn_out_path = outdir + outnam_g + '_fn.jpg'\n",
    "fp_out_path = outdir + outnam_g + '_fp.jpg'\n",
    "fnz_combined = cv2.cvtColor(fnz_combined, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite(fn_out_path, fnz_combined)\n",
    "fpz_combined = cv2.cvtColor(fpz_combined, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite(fp_out_path, fpz_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conf_mat_plot_heatmap_blankTN(cm, display_labels, title_in, heatmap_type='true'):\n",
    "    if len(display_labels) == 2:\n",
    "        fig, ax = plt.subplots(figsize=(6,4.5))\n",
    "    else:\n",
    "        fig, ax = plt.subplots(figsize=(12,9))\n",
    "    n_classes = cm.shape[0]\n",
    "    cmap = 'Greys'\n",
    "\n",
    "    if heatmap_type == 'percent':\n",
    "        sum_vals = np.sum(cm)\n",
    "    elif heatmap_type == 'true':\n",
    "        sum_vals = np.reshape(np.repeat(np.sum(cm, axis=1), n_classes), (n_classes, n_classes))\n",
    "    elif heatmap_type == 'pred':\n",
    "        sum_vals = np.reshape(np.tile(np.sum(cm, axis=0), n_classes), (n_classes, n_classes))\n",
    "        print(sum_vals)\n",
    "\n",
    "    color_mapping = np.array(np.multiply(np.divide(cm, sum_vals), 255), np.uint8)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        for j in range(n_classes):\n",
    "            if i == 0 and j == 0:\n",
    "                text_cm = \"\"\n",
    "            else:\n",
    "                text_cm = format(cm[i, j], ',')\n",
    "            txt_color = [1, 1, 1] if color_mapping[i, j] > 100 else [0, 0, 0]\n",
    "            ax.text(j, i, text_cm, ha=\"center\", va=\"center\", color=txt_color, fontsize=18)\n",
    "            ax.axhline(i - .5, color='black', linewidth=1.0)\n",
    "            ax.axvline(j - .5, color='black', linewidth=1.0)\n",
    "\n",
    "    ax.matshow(color_mapping, cmap=cmap)\n",
    "\n",
    "    ax.set_xlabel(\"Predicted label\", fontsize=16)\n",
    "    ax.set_ylabel(\"True label\", fontsize=16)\n",
    "    ax.set_xticks(np.arange(n_classes))\n",
    "    ax.set_yticks(np.arange(n_classes))\n",
    "    ax.set_xticklabels(display_labels, fontsize=16)\n",
    "    ax.set_yticklabels(display_labels, fontsize=16)\n",
    "    ax.set_title(title_in, fontsize=16)\n",
    "    ax.tick_params(bottom=True, labelbottom=True, top=False, labeltop=False)\n",
    "\n",
    "    ax.set_ylim((n_classes - 0.5, -0.5))\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_mat_raw(true, predicted, labels):\n",
    "    mat_out = np.empty((len(labels), len(labels)))\n",
    "    for i, row in enumerate(labels):\n",
    "        preds_row = predicted[true == row]\n",
    "        for j, col in enumerate(labels):\n",
    "            mat_out[i, j] = np.sum(preds_row == col)\n",
    "    mat_out = np.array(mat_out, dtype=np.int)\n",
    "    return mat_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-backup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_conf_mat_plot(cm, labels, title, results_dir, prefix):\n",
    "    n_class = len(labels)\n",
    "    cm_all = np.reshape(np.array(cm, dtype=np.int), (n_class, n_class))\n",
    "    cm_out = conf_mat_plot_heatmap_blankTN(cm_all, labels, title)\n",
    "    out_path = prefix + '_confidence_matrix.png'\n",
    "    results_dir = Path(results_dir)\n",
    "    cm_out.get_figure().savefig(results_dir / out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-makeup",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfrc_results['tru_class_bin'] = np.array(gfrc_results.tru_class > 0, dtype=np.int)\n",
    "cm_gfrc = conf_mat_raw(gfrc_results.tru_class_bin, gfrc_results.pred_class, [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-atlantic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"/home/cmf21/pytorch_save/output_for_draft/\"\n",
    "title = \"\"\n",
    "labels = [\"none\", \"animal\"]\n",
    "affix = 'gfrc_' + experiment + '_test'\n",
    "# blank\n",
    "# springbok 1 (0+1) code=bok\n",
    "# oryx 2 (1+1) code=oryx\n",
    "# kudu 3 (2+1) code=kudu\n",
    "# zebra 4 (3+1) code=zeb\n",
    "# ostrich 5 (4+1) code=ost\n",
    "# unidentified 6 (5+1) code=unid\n",
    "save_conf_mat_plot(cm_gfrc, labels, title, outdir, affix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(outdir + 'gfrc_rgb_baseline2_test_confidence_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-shirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(outdir + 'gfrc_meta_ci_end_test_confidence_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-evanescence",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(outdir + 'gfrc_gfrc_rgb_bin_confidence_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(outdir + 'gfrc_gfrc_meta_prediction_confidence_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(outdir + 'gfrc_meta_prediction_end_confidence_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(outdir + 'gfrc_meta_prediction_norm_confidence_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-saver",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(outdir + 'gfrc_meta_prediction_ci_confidence_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(outdir + 'gfrc_meta_pred_ci_spread_confidence_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "conf_mat_plot_heatmap_blankTN(np.array([[0, 3391],[143,343]]), \n",
    "                              [\"none\", \"animal\"], \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-absolute",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def conf_mat_plot_heatmap_blankTN2(cm, display_labels, heatmap_type='true'):\n",
    "    if len(display_labels) == 2:\n",
    "        fig, ax = plt.subplots(figsize=(6,4.5))\n",
    "    else:\n",
    "        fig, ax = plt.subplots(figsize=(12,9))\n",
    "    n_classes = cm.shape[0]\n",
    "    cmap = 'Greys'\n",
    "\n",
    "    if heatmap_type == 'percent':\n",
    "        sum_vals = np.sum(cm)\n",
    "    elif heatmap_type == 'true':\n",
    "        sum_vals = np.reshape(np.repeat(np.sum(cm, axis=1), n_classes), (n_classes, n_classes))\n",
    "    elif heatmap_type == 'pred':\n",
    "        sum_vals = np.reshape(np.tile(np.sum(cm, axis=0), n_classes), (n_classes, n_classes))\n",
    "        print(sum_vals)\n",
    "\n",
    "    color_mapping = np.array(np.multiply(np.divide(cm, sum_vals), 255), np.uint8)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        for j in range(n_classes):\n",
    "            if i == 0 and j == 0:\n",
    "                text_cm = \"\"\n",
    "            else:\n",
    "                text_cm = format(cm[i, j], ',')\n",
    "            txt_color = [1, 1, 1] if color_mapping[i, j] > 100 else [0, 0, 0]\n",
    "            ax.text(j, i, text_cm, ha=\"center\", va=\"center\", color=txt_color, fontsize=18)\n",
    "            ax.axhline(i - .5, color='black', linewidth=1.0)\n",
    "            ax.axvline(j - .5, color='black', linewidth=1.0)\n",
    "\n",
    "    ax.matshow(color_mapping, cmap=cmap)\n",
    "\n",
    "    ax.set_xlabel(\"Predicted label\", fontsize=16)\n",
    "    ax.set_ylabel(\"True label\", fontsize=16)\n",
    "    ax.set_xticks(np.arange(n_classes))\n",
    "    ax.set_yticks(np.arange(n_classes))\n",
    "    ax.set_xticklabels(display_labels, fontsize=16)\n",
    "    ax.set_yticklabels(display_labels, fontsize=16)\n",
    "    ax.tick_params(bottom=True, labelbottom=True, top=False, labeltop=False)\n",
    "\n",
    "    ax.set_ylim((n_classes - 0.5, -0.5))\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-daniel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def save_conf_mat_plot_ed(cm, labels, results_dir, prefix):\n",
    "    n_class = len(labels)\n",
    "    cm_all = np.reshape(np.array(cm, dtype=np.int), (n_class, n_class))\n",
    "    cm_out = conf_mat_plot_heatmap_blankTN2(cm_all, labels)\n",
    "    out_path = prefix + '_confidence_matrix.png'\n",
    "    results_dir = Path(results_dir)\n",
    "    cm_out.get_figure().savefig(results_dir / out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-genealogy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "output_dir = \"/home/cmf21/pytorch_save/output_for_draft/\"\n",
    "exp1 = \"gfrc_meta_prediction\"\n",
    "gfrc_results1 = pd.read_csv(output_dir + 'gfrc_' + exp1 + \"_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "gfrc_results1['tru_class_bin'] = np.array(gfrc_results1.tru_class > 0, dtype=np.int)\n",
    "cm_gfrc1 = conf_mat_raw(gfrc_results1.tru_class_bin, gfrc_results1.pred_class, [0,1])\n",
    "cm_gfrc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"none\", \"animal\"]\n",
    "\n",
    "save_conf_mat_plot_ed(cm_gfrc1, labels, output_dir, exp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp2 = \"meta_prediction_end\"\n",
    "gfrc_results2 = pd.read_csv(output_dir + 'gfrc_' + exp2 + \"_results.csv\")\n",
    "gfrc_results2['tru_class_bin'] = np.array(gfrc_results2.tru_class > 0, dtype=np.int)\n",
    "cm_gfrc2 = conf_mat_raw(gfrc_results2.tru_class_bin, gfrc_results2.pred_class, [0,1])\n",
    "save_conf_mat_plot_ed(cm_gfrc2, labels, output_dir, exp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp3 = \"meta_prediction_ci\"\n",
    "gfrc_results3 = pd.read_csv(output_dir + 'gfrc_' + exp3 + \"_results.csv\")\n",
    "gfrc_results3['tru_class_bin'] = np.array(gfrc_results3.tru_class > 0, dtype=np.int)\n",
    "cm_gfrc3 = conf_mat_raw(gfrc_results3.tru_class_bin, gfrc_results3.pred_class, [0,1])\n",
    "save_conf_mat_plot_ed(cm_gfrc3, labels, output_dir, exp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-enzyme",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp4 = \"meta_pred_ci_spread\"\n",
    "gfrc_results4 = pd.read_csv(output_dir + 'gfrc_' + exp4 + \"_results.csv\")\n",
    "gfrc_results4['tru_class_bin'] = np.array(gfrc_results4.tru_class > 0, dtype=np.int)\n",
    "cm_gfrc4 = conf_mat_raw(gfrc_results4.tru_class_bin, gfrc_results4.pred_class, [0,1])\n",
    "save_conf_mat_plot_ed(cm_gfrc4, labels, output_dir, exp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp5 = \"meta_ci_end\"\n",
    "gfrc_results5 = pd.read_csv(output_dir + 'gfrc_' + exp5 + \"_results.csv\")\n",
    "gfrc_results5['tru_class_bin'] = np.array(gfrc_results5.tru_class > 0, dtype=np.int)\n",
    "cm_gfrc5 = conf_mat_raw(gfrc_results5.tru_class_bin, gfrc_results5.pred_class, [0,1])\n",
    "save_conf_mat_plot_ed(cm_gfrc5, labels, output_dir, exp5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp6 = \"gfrc_rgb_bin\"\n",
    "gfrc_results6 = pd.read_csv(output_dir + 'gfrc_' + exp6 + \"_results.csv\")\n",
    "gfrc_results6['tru_class_bin'] = np.array(gfrc_results6.tru_class > 0, dtype=np.int)\n",
    "cm_gfrc6 = conf_mat_raw(gfrc_results6.tru_class_bin, gfrc_results6.pred_class, [0,1])\n",
    "save_conf_mat_plot_ed(cm_gfrc6, labels, output_dir, exp6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-genre",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
